{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3ab87d2f",
      "metadata": {
        "id": "3ab87d2f"
      },
      "source": [
        "## Help Twitter Combat Hate Speech Using NLP and ML"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9eea0c4e",
      "metadata": {
        "id": "9eea0c4e"
      },
      "source": [
        "\n",
        "Twitter is the biggest platform where anybody and everybody can have their views heard. Some of these voices spread hate and negativity. Twitter is wary of its platform being used as a medium to spread hate.\n",
        "\n",
        "You are a data scientist at Twitter, and you will help Twitter in identifying the tweets with hate speech and removing them from the platform. You will use NLP techniques, perform specific cleanup for tweets data, and make a robust model.\n",
        "\n",
        "Domain: Social Media\n",
        "\n",
        "Analysis to be done: Clean up tweets and build a classification model by using NLP techniques, cleanup specific for tweets data, regularization and hyperparameter tuning using stratified k-fold and cross validation to get the best model.\n",
        "\n",
        "Content:\n",
        "\n",
        "id: identifier number of the tweet\n",
        "\n",
        "Label: 0 (non-hate) /1 (hate)\n",
        "\n",
        "Tweet: the text in the tweet\n",
        "\n",
        "Tasks:\n",
        "\n",
        "1, Load the tweets file using read_csv function from Pandas package.\n",
        "\n",
        "2, Get the tweets into a list for easy text cleanup and manipulation.\n",
        "\n",
        "To cleanup:\n",
        "\n",
        "--- Normalize the casing.\n",
        "\n",
        "--- Using regular expressions, remove user handles. These begin with '@’.\n",
        "\n",
        "--- Using regular expressions, remove URLs.\n",
        "\n",
        "--- Using TweetTokenizer from NLTK, tokenize the tweets into individual terms.\n",
        "\n",
        "--- Remove stop words.\n",
        "\n",
        "--- Remove redundant terms like ‘amp’, ‘rt’, etc.\n",
        "\n",
        "--- Remove ‘#’ symbols from the tweet while retaining the term.\n",
        "\n",
        "(4), Extra cleanup by removing terms with a length of 1.\n",
        "\n",
        "(5), Check out the top terms in the tweets:\n",
        "\n",
        "--- First, get all the tokenized terms into one large list.\n",
        "\n",
        "--- Use the counter and find the 10 most common terms.\n",
        "\n",
        "(6), Data formatting for predictive modeling:\n",
        "\n",
        "---Join the tokens back to form strings. This will be required for the vectorizers.\n",
        "\n",
        "---Assign x and y.\n",
        "\n",
        "---Perform train_test_split using sklearn.\n",
        "\n",
        "(7), We’ll use TF-IDF values for the terms as a feature to get into a vector space model.\n",
        "\n",
        "---Import TF-IDF vectorizer from sklearn.\n",
        "\n",
        "---Instantiate with a maximum of 5000 terms in your vocabulary.\n",
        "\n",
        "---Fit and apply on the train set.\n",
        "\n",
        "---Apply on the test set.\n",
        "\n",
        "(8), Model building: Ordinary Logistic Regression\n",
        "\n",
        "---Instantiate Logistic Regression from sklearn with default parameters.\n",
        "\n",
        "---Fit into the train data.\n",
        "\n",
        "---Make predictions for the train and the test set.\n",
        "\n",
        "(9), Model evaluation: Accuracy, recall, and f_1 score.\n",
        "\n",
        "Report the accuracy on the train set.\n",
        "\n",
        "---Report the recall on the train set: decent, high, or low.\n",
        "\n",
        "---Get the f1 score on the train set.\n",
        "\n",
        "(10), Looks like you need to adjust the class imbalance, as the model seems to focus on the 0s.\n",
        "\n",
        "---Adjust the appropriate class in the LogisticRegression model.\n",
        "\n",
        "(11), Train again with the adjustment and evaluate.\n",
        "\n",
        "---Train the model on the train set.\n",
        "\n",
        "---Evaluate the predictions on the train set: accuracy, recall, and f_1 score.\n",
        "\n",
        "(12), Regularization and Hyperparameter tuning:\n",
        "\n",
        "---Import GridSearch and StratifiedKFold because of class imbalance.\n",
        "\n",
        "---Provide the parameter grid to choose for ‘C’ and ‘penalty’ parameters.\n",
        "\n",
        "---Use a balanced class weight while instantiating the logistic regression.\n",
        "\n",
        "(13), Find the parameters with the best recall in cross-validation.\n",
        "\n",
        "---Choose ‘recall’ as the metric for scoring.\n",
        "\n",
        "---Choose a stratified 4 fold cross-validation scheme.\n",
        "\n",
        "---Fit into the train set.\n",
        "\n",
        "(14), What are the best parameters?\n",
        "\n",
        "(15), Predict and evaluate using the best estimator.\n",
        "\n",
        "---Use the best estimator from the grid search to make predictions on the test set.\n",
        "\n",
        "---What is the recall on the test set for the toxic comments?\n",
        "\n",
        "---What is the f_1 score?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5401faf",
      "metadata": {
        "id": "d5401faf"
      },
      "source": [
        "### import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b3d57ac",
      "metadata": {
        "id": "7b3d57ac"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.classify import SklearnClassifier\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from subprocess import check_output\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import re\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "#nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "#from nltk.stem.porter import PorterStemme\n",
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0f1e378-f8f6-4272-9e60-372a8842fbff",
      "metadata": {
        "tags": [],
        "id": "e0f1e378-f8f6-4272-9e60-372a8842fbff"
      },
      "outputs": [],
      "source": [
        "# import nltk\n",
        "# nltk.download('all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "307d04d5-6919-461f-8a1d-79ad7f36e49b",
      "metadata": {
        "id": "307d04d5-6919-461f-8a1d-79ad7f36e49b"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f3cf3cd",
      "metadata": {
        "id": "6f3cf3cd"
      },
      "source": [
        "## 1. Load tweets file using read_csv function from Pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6f8c2d8",
      "metadata": {
        "id": "b6f8c2d8",
        "outputId": "46e9638a-3618-4bd1-f9da-b308b9eccd4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(31962, 3)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import dataset\n",
        "Twitter_Data = pd.read_csv('TwitterHate.csv')\n",
        "Twitter_Data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fefd8e15",
      "metadata": {
        "id": "fefd8e15",
        "outputId": "684fc7a1-09e4-43c7-b585-9c7b1e420c98"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet\n",
              "0   1      0   @user when a father is dysfunctional and is s...\n",
              "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
              "2   3      0                                bihday your majesty"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Twitter_Data.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78a0beff",
      "metadata": {
        "id": "78a0beff",
        "outputId": "c0c72121-69fc-481c-e888-fd4c078e3345"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(31962, 2)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Retain only neccessary columns\n",
        "Twitter_Data = Twitter_Data[['label','tweet']]\n",
        "Twitter_Data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bd76d69",
      "metadata": {
        "id": "2bd76d69",
        "outputId": "aa2fee81-0bfc-4550-8e5b-5bdbdb6369fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    29720\n",
              "1     2242\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Twitter_Data.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2920bb4-fcf6-4a9e-8c42-a787157793f1",
      "metadata": {
        "id": "a2920bb4-fcf6-4a9e-8c42-a787157793f1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c437f2e5-8ebc-4126-b303-9fcc71a77542",
      "metadata": {
        "id": "c437f2e5-8ebc-4126-b303-9fcc71a77542"
      },
      "outputs": [],
      "source": [
        "def preprocessing(data):\n",
        "    stemmer = nltk.stem.RSLPStemmer()\n",
        "    all_stopwords = stopwords.words('english')\n",
        "    all_stopwords.remove('not')\n",
        "    corpus = []\n",
        "    for tweet in data:\n",
        "\n",
        "        review = re.sub(r\"@[A-Za-z0-9_]+\", \" \", tweet)\n",
        "        review = re.sub('RT', ' ', review)\n",
        "        review = re.sub(r\"https?://[A-Za-z0-9./]+\", \" \", review)\n",
        "        review = re.sub(r\"https?\", \" \", review)\n",
        "        review = re.sub('[^a-zA-Z]', ' ', review)\n",
        "        review = review.lower()\n",
        "        review = review.split()\n",
        "        ps = PorterStemmer()\n",
        "        review = [ps.stem(word) for word in review if not word in set(all_stopwords) if len(word) > 2]\n",
        "        review = ' '.join(review)\n",
        "        corpus.append(review)\n",
        "\n",
        "    return np.array(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5d5a1ae-0e29-416e-ba8d-d29d3fccede2",
      "metadata": {
        "id": "f5d5a1ae-0e29-416e-ba8d-d29d3fccede2"
      },
      "outputs": [],
      "source": [
        "Twitter_Data['cleen_tweet'] = preprocessing(Twitter_Data['tweet'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9af01f9f-6be4-4efc-a6f7-4dc84fe318b8",
      "metadata": {
        "id": "9af01f9f-6be4-4efc-a6f7-4dc84fe318b8",
        "outputId": "c6e47512-a69b-4903-cf5c-10eef722ca4d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleen_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>father dysfunct selfish drag kid dysfunct run</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thank lyft credit use caus offer wheelchair va...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday majesti</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>model love take time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguid societi motiv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                              tweet  \\\n",
              "0      0   @user when a father is dysfunctional and is s...   \n",
              "1      0  @user @user thanks for #lyft credit i can't us...   \n",
              "2      0                                bihday your majesty   \n",
              "3      0  #model   i love u take with u all the time in ...   \n",
              "4      0             factsguide: society now    #motivation   \n",
              "\n",
              "                                         cleen_tweet  \n",
              "0      father dysfunct selfish drag kid dysfunct run  \n",
              "1  thank lyft credit use caus offer wheelchair va...  \n",
              "2                                     bihday majesti  \n",
              "3                               model love take time  \n",
              "4                            factsguid societi motiv  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Twitter_Data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18d1384f",
      "metadata": {
        "id": "18d1384f"
      },
      "source": [
        "###  Data formatting for predictive modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b9a0949",
      "metadata": {
        "id": "4b9a0949",
        "outputId": "62d7b204-6b46-4119-fc46-bdc28da466b4",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(31962,)\n",
            "(31962,)\n"
          ]
        }
      ],
      "source": [
        "X = Twitter_Data.cleen_tweet\n",
        "y = Twitter_Data.label\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c79c21e4",
      "metadata": {
        "id": "c79c21e4"
      },
      "source": [
        "####  Perform train_test_split using sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cd358be",
      "metadata": {
        "id": "3cd358be",
        "outputId": "b18729a4-681e-4e3a-bfab-5478e8e31733"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(23971,)\n",
            "(7991,)\n",
            "(23971,)\n",
            "(7991,)\n"
          ]
        }
      ],
      "source": [
        "# split X and y into training ans testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d1e501a",
      "metadata": {
        "id": "5d1e501a"
      },
      "source": [
        "###  Use TF-IDF values for the terms as a feature to get into a vector space model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a30436b",
      "metadata": {
        "id": "8a30436b"
      },
      "source": [
        "#### 1. Import TF-IDF vectorizer from sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdb683f9",
      "metadata": {
        "id": "cdb683f9"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b3cbe6d",
      "metadata": {
        "id": "6b3cbe6d"
      },
      "source": [
        "#### 2. Instantiate with a maximum of 5000 terms in your vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ef31485",
      "metadata": {
        "id": "8ef31485"
      },
      "outputs": [],
      "source": [
        "# instantiate the vectorizer\n",
        "vect_tfidf = TfidfVectorizer(analyzer='word')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5db028c",
      "metadata": {
        "id": "d5db028c"
      },
      "source": [
        "#### 3. Fit and apply on the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "092f0d12",
      "metadata": {
        "id": "092f0d12"
      },
      "outputs": [],
      "source": [
        "vect_tfidf.fit(X_train)\n",
        "X_train_tfidf_dtm = vect_tfidf.transform(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da8e85be",
      "metadata": {
        "id": "da8e85be",
        "outputId": "703bb49b-490e-4382-fea2-cfc37e58fae5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aaa</th>\n",
              "      <th>aaaaa</th>\n",
              "      <th>aaaaaand</th>\n",
              "      <th>aaaaah</th>\n",
              "      <th>aaaaand</th>\n",
              "      <th>aaahh</th>\n",
              "      <th>aaahhhh</th>\n",
              "      <th>aaahhhhh</th>\n",
              "      <th>aaand</th>\n",
              "      <th>aaawwwww</th>\n",
              "      <th>...</th>\n",
              "      <th>zovik</th>\n",
              "      <th>zpamdelacruz</th>\n",
              "      <th>zshq</th>\n",
              "      <th>zucchini</th>\n",
              "      <th>zuma</th>\n",
              "      <th>zumba</th>\n",
              "      <th>zurich</th>\n",
              "      <th>zydeco</th>\n",
              "      <th>zzz</th>\n",
              "      <th>zzzzzzzz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23966</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23967</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23968</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23969</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23970</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23971 rows × 25892 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       aaa  aaaaa  aaaaaand  aaaaah  aaaaand  aaahh  aaahhhh  aaahhhhh  aaand  \\\n",
              "0      0.0    0.0       0.0     0.0      0.0    0.0      0.0       0.0    0.0   \n",
              "1      0.0    0.0       0.0     0.0      0.0    0.0      0.0       0.0    0.0   \n",
              "2      0.0    0.0       0.0     0.0      0.0    0.0      0.0       0.0    0.0   \n",
              "3      0.0    0.0       0.0     0.0      0.0    0.0      0.0       0.0    0.0   \n",
              "4      0.0    0.0       0.0     0.0      0.0    0.0      0.0       0.0    0.0   \n",
              "...    ...    ...       ...     ...      ...    ...      ...       ...    ...   \n",
              "23966  0.0    0.0       0.0     0.0      0.0    0.0      0.0       0.0    0.0   \n",
              "23967  0.0    0.0       0.0     0.0      0.0    0.0      0.0       0.0    0.0   \n",
              "23968  0.0    0.0       0.0     0.0      0.0    0.0      0.0       0.0    0.0   \n",
              "23969  0.0    0.0       0.0     0.0      0.0    0.0      0.0       0.0    0.0   \n",
              "23970  0.0    0.0       0.0     0.0      0.0    0.0      0.0       0.0    0.0   \n",
              "\n",
              "       aaawwwww  ...  zovik  zpamdelacruz  zshq  zucchini  zuma  zumba  \\\n",
              "0           0.0  ...    0.0           0.0   0.0       0.0   0.0    0.0   \n",
              "1           0.0  ...    0.0           0.0   0.0       0.0   0.0    0.0   \n",
              "2           0.0  ...    0.0           0.0   0.0       0.0   0.0    0.0   \n",
              "3           0.0  ...    0.0           0.0   0.0       0.0   0.0    0.0   \n",
              "4           0.0  ...    0.0           0.0   0.0       0.0   0.0    0.0   \n",
              "...         ...  ...    ...           ...   ...       ...   ...    ...   \n",
              "23966       0.0  ...    0.0           0.0   0.0       0.0   0.0    0.0   \n",
              "23967       0.0  ...    0.0           0.0   0.0       0.0   0.0    0.0   \n",
              "23968       0.0  ...    0.0           0.0   0.0       0.0   0.0    0.0   \n",
              "23969       0.0  ...    0.0           0.0   0.0       0.0   0.0    0.0   \n",
              "23970       0.0  ...    0.0           0.0   0.0       0.0   0.0    0.0   \n",
              "\n",
              "       zurich  zydeco  zzz  zzzzzzzz  \n",
              "0         0.0     0.0  0.0       0.0  \n",
              "1         0.0     0.0  0.0       0.0  \n",
              "2         0.0     0.0  0.0       0.0  \n",
              "3         0.0     0.0  0.0       0.0  \n",
              "4         0.0     0.0  0.0       0.0  \n",
              "...       ...     ...  ...       ...  \n",
              "23966     0.0     0.0  0.0       0.0  \n",
              "23967     0.0     0.0  0.0       0.0  \n",
              "23968     0.0     0.0  0.0       0.0  \n",
              "23969     0.0     0.0  0.0       0.0  \n",
              "23970     0.0     0.0  0.0       0.0  \n",
              "\n",
              "[23971 rows x 25892 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a dataframe\n",
        "feature_names = vect_tfidf.get_feature_names_out ()\n",
        "pd.DataFrame(X_train_tfidf_dtm.toarray(), columns=feature_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7405e77",
      "metadata": {
        "id": "a7405e77"
      },
      "source": [
        "#### 4. Apply on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11770851",
      "metadata": {
        "id": "11770851"
      },
      "outputs": [],
      "source": [
        "#vectorizer.transform\n",
        "#vect_tfidf.fit(X_test)\n",
        "X_test_tfidf_dtm = vect_tfidf.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd3d570b",
      "metadata": {
        "id": "fd3d570b",
        "outputId": "9e87324a-88fe-4feb-ba18-2ea12ade4981"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aaa</th>\n",
              "      <th>aaaaa</th>\n",
              "      <th>aaaaaand</th>\n",
              "      <th>aaaaah</th>\n",
              "      <th>aaaaand</th>\n",
              "      <th>aaahh</th>\n",
              "      <th>aaahhhh</th>\n",
              "      <th>aaahhhhh</th>\n",
              "      <th>aaand</th>\n",
              "      <th>aaawwwww</th>\n",
              "      <th>...</th>\n",
              "      <th>zovik</th>\n",
              "      <th>zpamdelacruz</th>\n",
              "      <th>zshq</th>\n",
              "      <th>zucchini</th>\n",
              "      <th>zuma</th>\n",
              "      <th>zumba</th>\n",
              "      <th>zurich</th>\n",
              "      <th>zydeco</th>\n",
              "      <th>zzz</th>\n",
              "      <th>zzzzzzzz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7986</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7987</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7988</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7989</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7990</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7991 rows × 25892 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      aaa  aaaaa  aaaaaand  aaaaah  aaaaand  aaahh  aaahhhh  aaahhhhh  aaand  \\\n",
              "0     0.0    0.0       0.0     0.0      0.0    0.0      0.0       0.0    0.0   \n",
              "1     0.0    0.0       0.0     0.0      0.0    0.0      0.0       0.0    0.0   \n",
              "2     0.0    0.0       0.0     0.0      0.0    0.0      0.0       0.0    0.0   \n",
              "3     0.0    0.0       0.0     0.0      0.0    0.0      0.0       0.0    0.0   \n",
              "4     0.0    0.0       0.0     0.0      0.0    0.0      0.0       0.0    0.0   \n",
              "...   ...    ...       ...     ...      ...    ...      ...       ...    ...   \n",
              "7986  0.0    0.0       0.0     0.0      0.0    0.0      0.0       0.0    0.0   \n",
              "7987  0.0    0.0       0.0     0.0      0.0    0.0      0.0       0.0    0.0   \n",
              "7988  0.0    0.0       0.0     0.0      0.0    0.0      0.0       0.0    0.0   \n",
              "7989  0.0    0.0       0.0     0.0      0.0    0.0      0.0       0.0    0.0   \n",
              "7990  0.0    0.0       0.0     0.0      0.0    0.0      0.0       0.0    0.0   \n",
              "\n",
              "      aaawwwww  ...  zovik  zpamdelacruz  zshq  zucchini  zuma  zumba  zurich  \\\n",
              "0          0.0  ...    0.0           0.0   0.0       0.0   0.0    0.0     0.0   \n",
              "1          0.0  ...    0.0           0.0   0.0       0.0   0.0    0.0     0.0   \n",
              "2          0.0  ...    0.0           0.0   0.0       0.0   0.0    0.0     0.0   \n",
              "3          0.0  ...    0.0           0.0   0.0       0.0   0.0    0.0     0.0   \n",
              "4          0.0  ...    0.0           0.0   0.0       0.0   0.0    0.0     0.0   \n",
              "...        ...  ...    ...           ...   ...       ...   ...    ...     ...   \n",
              "7986       0.0  ...    0.0           0.0   0.0       0.0   0.0    0.0     0.0   \n",
              "7987       0.0  ...    0.0           0.0   0.0       0.0   0.0    0.0     0.0   \n",
              "7988       0.0  ...    0.0           0.0   0.0       0.0   0.0    0.0     0.0   \n",
              "7989       0.0  ...    0.0           0.0   0.0       0.0   0.0    0.0     0.0   \n",
              "7990       0.0  ...    0.0           0.0   0.0       0.0   0.0    0.0     0.0   \n",
              "\n",
              "      zydeco  zzz  zzzzzzzz  \n",
              "0        0.0  0.0       0.0  \n",
              "1        0.0  0.0       0.0  \n",
              "2        0.0  0.0       0.0  \n",
              "3        0.0  0.0       0.0  \n",
              "4        0.0  0.0       0.0  \n",
              "...      ...  ...       ...  \n",
              "7986     0.0  0.0       0.0  \n",
              "7987     0.0  0.0       0.0  \n",
              "7988     0.0  0.0       0.0  \n",
              "7989     0.0  0.0       0.0  \n",
              "7990     0.0  0.0       0.0  \n",
              "\n",
              "[7991 rows x 25892 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a dataframe\n",
        "feature_names_test = vect_tfidf.get_feature_names_out ()\n",
        "pd.DataFrame(X_test_tfidf_dtm.toarray(), columns=feature_names_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d385e20",
      "metadata": {
        "id": "4d385e20"
      },
      "source": [
        "###  Model building: Ordinary Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "219023a6",
      "metadata": {
        "id": "219023a6"
      },
      "source": [
        "#### 1. Instantiate Logistic Regression from sklearn with default parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f37382a7",
      "metadata": {
        "id": "f37382a7"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression(random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d9203fb",
      "metadata": {
        "id": "4d9203fb",
        "outputId": "8e36e6ee-8114-4b2a-97d3-939e596d5372"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(random_state=0)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr.fit(X_train_tfidf_dtm, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92385818",
      "metadata": {
        "id": "92385818"
      },
      "source": [
        "#### 3. Make predictions for the train and the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00087ff3",
      "metadata": {
        "id": "00087ff3"
      },
      "outputs": [],
      "source": [
        "# make class predictions for X_test_dtm\n",
        "y_pred_class_train = lr.predict(X_train_tfidf_dtm)\n",
        "y_pred_class_test = lr.predict(X_test_tfidf_dtm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c841b8da",
      "metadata": {
        "id": "c841b8da"
      },
      "source": [
        "###  Model evaluation: Accuracy, recall, and f_1 score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1786484a",
      "metadata": {
        "id": "1786484a"
      },
      "source": [
        "#### 1. Report the accuracy on the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78f4f514",
      "metadata": {
        "id": "78f4f514",
        "outputId": "9233120a-d17e-47de-f431-a2c2e3a8ea01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9537774811230236"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate accuracy of class predictions\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score_train = accuracy_score(y_train, y_pred_class_train)\n",
        "accuracy_score_train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c556a742",
      "metadata": {
        "id": "c556a742"
      },
      "source": [
        "#### 2. Report the recall on the train set: decent, high, or low"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2e9eb3f",
      "metadata": {
        "id": "a2e9eb3f",
        "outputId": "52f3c2ef-f432-44a9-db40-cf583898bc40"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6826401664214806"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import recall_score\n",
        "recall_metric = recall_score(y_train, y_pred_class_train, average = \"macro\")\n",
        "recall_metric"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3560b1e0",
      "metadata": {
        "id": "3560b1e0"
      },
      "source": [
        "#### 3. Get the f1 score on the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbc0d761",
      "metadata": {
        "id": "cbc0d761",
        "outputId": "a0f9767a-2bcd-434c-a95f-48b67e86bc8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.752702833659725"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score = f1_score(y_train, y_pred_class_train, average = \"macro\")\n",
        "f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6b82821",
      "metadata": {
        "id": "d6b82821",
        "outputId": "667fde06-ccf1-4fcb-9976-adeeb7a4d13d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[22239    30]\n",
            " [ 1078   624]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_train,y_pred_class_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68a80cf6",
      "metadata": {
        "id": "68a80cf6"
      },
      "source": [
        "### Adjust the class imbalance, as the model seems to focus on the 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22a1c383",
      "metadata": {
        "id": "22a1c383"
      },
      "source": [
        "#### 1. Adjust the appropriate class in the LogisticRegression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7dc4322",
      "metadata": {
        "id": "c7dc4322"
      },
      "outputs": [],
      "source": [
        "wlr = LogisticRegression(random_state=1, class_weight=\"balanced\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08adcfbf",
      "metadata": {
        "id": "08adcfbf"
      },
      "source": [
        "###  Train again with the adjustment and evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82b9d473",
      "metadata": {
        "id": "82b9d473"
      },
      "source": [
        "####1. Train the model on the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe0eac16",
      "metadata": {
        "id": "fe0eac16"
      },
      "outputs": [],
      "source": [
        "wlr.fit(X_train_tfidf_dtm, y_train)\n",
        "\n",
        "wlr_y_pred_class_train = wlr.predict(X_train_tfidf_dtm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68973826",
      "metadata": {
        "id": "68973826"
      },
      "source": [
        "#### 2. Evaluate the predictions on the train set: accuracy, recall, and f_1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "404bdb8f",
      "metadata": {
        "id": "404bdb8f",
        "outputId": "1480400a-bf03-4e32-d0a5-fc8f0fd3c9c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9658337157398523"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wlr_accuracy_score_train = accuracy_score(y_train, wlr_y_pred_class_train)\n",
        "wlr_accuracy_score_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf870bbe",
      "metadata": {
        "id": "bf870bbe",
        "outputId": "583650aa-154d-4e7a-f1ab-8f36cc87d485"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9775414189675973"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wlr_recall_metric = recall_score(y_train, wlr_y_pred_class_train, average = \"macro\")\n",
        "wlr_recall_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "862d86e6",
      "metadata": {
        "id": "862d86e6",
        "outputId": "13565e45-6bad-4e9e-a0e3-d5303343cf80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8929770147667768"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "wlr_f1_score = f1_score(y_train, wlr_y_pred_class_train, average = \"macro\")\n",
        "wlr_f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faaa2553",
      "metadata": {
        "id": "faaa2553",
        "outputId": "cff55b49-4edb-49b6-f4c4-796c29c22beb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[21465   804]\n",
            " [   15  1687]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_train,wlr_y_pred_class_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d72f8fa3",
      "metadata": {
        "id": "d72f8fa3"
      },
      "source": [
        "##### By changing class_weight from none to balanced, F1 score has improved to 0.89 from 0.72 and FN has reduced to 16 from 1156 and FP has increased to 802 from 19"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f757306a",
      "metadata": {
        "id": "f757306a"
      },
      "source": [
        "###  Regularization and Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fca69a55",
      "metadata": {
        "id": "fca69a55"
      },
      "source": [
        "#### 1. Import GridSearch and StratifiedKFold because of class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ce3fc9e",
      "metadata": {
        "id": "9ce3fc9e"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import GridSearchCV,StratifiedKFold"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcf0bf8b",
      "metadata": {
        "id": "bcf0bf8b"
      },
      "source": [
        "#### 2. Provide the parameter grid to choose for ‘C’ and ‘penalty’ parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42e789c8",
      "metadata": {
        "id": "42e789c8"
      },
      "outputs": [],
      "source": [
        "grid={\"C\": [1, 2], \"penalty\":[\"l2\"]}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5428dc13",
      "metadata": {
        "id": "5428dc13"
      },
      "source": [
        "#### 3. Use a balanced class weight while instantiating the logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f002408",
      "metadata": {
        "id": "1f002408"
      },
      "outputs": [],
      "source": [
        "logreg=LogisticRegression(class_weight=\"balanced\")\n",
        "logreg_cv=GridSearchCV(logreg,grid)\n",
        "logreg_cv.fit(X_train_tfidf_dtm,y_train)\n",
        "cv_y_pred_class_train = logreg_cv.predict(X_train_tfidf_dtm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8abaaa4b",
      "metadata": {
        "id": "8abaaa4b",
        "outputId": "ac694d5c-42bf-456b-c9e1-71edc0c47a9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9732176379792249"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wlr_accuracy_score_train = accuracy_score(y_train, cv_y_pred_class_train)\n",
        "wlr_accuracy_score_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47a0d47d",
      "metadata": {
        "id": "47a0d47d",
        "outputId": "9a563c0a-113d-4ab3-c7f8-2b04f1f8fdd2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.983686107781897"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wlr_recall_metric = recall_score(y_train, cv_y_pred_class_train, average = \"macro\")\n",
        "wlr_recall_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaedc7b1",
      "metadata": {
        "id": "aaedc7b1",
        "outputId": "fd7d1357-c4bd-4cd9-aa16-a96f3edf7996"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9130764971098893"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "wlr_f1_score = f1_score(y_train, cv_y_pred_class_train, average = \"macro\")\n",
        "wlr_f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10c28dd6",
      "metadata": {
        "id": "10c28dd6",
        "outputId": "83202b9d-17fc-4a38-f898-ee503d3532d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[21465   804]\n",
            " [   15  1687]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_train,wlr_y_pred_class_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05f842f5",
      "metadata": {
        "id": "05f842f5",
        "outputId": "9871c1fb-b0da-4077-d2f6-8a9f40d6931c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[21634   635]\n",
            " [    7  1695]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_train,cv_y_pred_class_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75623b61",
      "metadata": {
        "id": "75623b61"
      },
      "source": [
        "##### By applying gridsearch, F1 score has improved to 0.92 from 0.89 and FN has reduced to 5 from 16 and FP has reduced to 557 from 802"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ed92ec5",
      "metadata": {
        "id": "6ed92ec5"
      },
      "source": [
        "###  Find the parameters with the best recall in cross validation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b13ae645",
      "metadata": {
        "id": "b13ae645"
      },
      "source": [
        "#### 1. Choose ‘recall’ as the metric for scoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28c0b010",
      "metadata": {
        "id": "28c0b010"
      },
      "outputs": [],
      "source": [
        "logreg_KF=GridSearchCV(logreg,grid)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89722df7",
      "metadata": {
        "id": "89722df7"
      },
      "source": [
        "#### 2. Choose stratified 4 fold cross validation scheme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85faa2a8",
      "metadata": {
        "id": "85faa2a8",
        "outputId": "bbd1fe3c-e8c8-4636-f55d-632ffc88acd4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "from numpy import array\n",
        "from sklearn.model_selection import KFold,StratifiedKFold\n",
        "kf = KFold(n_splits=4)\n",
        "kf.get_n_splits(Twitter_Data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d295b5e0",
      "metadata": {
        "id": "d295b5e0"
      },
      "source": [
        "#### 3. Fit into the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a907a7a5",
      "metadata": {
        "collapsed": true,
        "id": "a907a7a5",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "7d435d6d-91fa-4119-a838-5e6c145d75ea",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recall score for fold1 is 0.9428097120984817\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recall score for fold2 is 0.939769916804312\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recall score for fold3 is 0.9415341719856793\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recall score for fold4 is 0.9393067536694248\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\HP\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "count = 0\n",
        "for train_index, test_index in kf.split(Twitter_Data):\n",
        "    KF_X_train, KF_X_test, KF_y_train, KF_y_test = Twitter_Data.tweet[train_index], Twitter_Data.tweet[test_index],\\\n",
        "    Twitter_Data.label[train_index],Twitter_Data.label[test_index]\n",
        "    KF_X_train_tfidf_dtm = vect_tfidf.transform(KF_X_train)\n",
        "    KF_X_test_tfidf_dtm = vect_tfidf.transform(KF_X_test)\n",
        "    count=count+1\n",
        "    logreg_KF.fit(KF_X_train_tfidf_dtm,KF_y_train)\n",
        "    KF_cv_y_pred_class_train = logreg_KF.predict(KF_X_train_tfidf_dtm)\n",
        "    KF_recall_metric = recall_score(KF_y_train, KF_cv_y_pred_class_train, average = \"macro\")\n",
        "    print(\"Recall score for fold\" + str(count) + \" is \" + str(KF_recall_metric))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd9afd07",
      "metadata": {
        "id": "cd9afd07"
      },
      "source": [
        "#### Recall score is pretty consistent across all 4 data distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2046a23",
      "metadata": {
        "id": "e2046a23"
      },
      "source": [
        "###  What are the best parameters?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a6a53a2",
      "metadata": {
        "id": "9a6a53a2",
        "outputId": "817c68d4-9f56-4bc2-ace1-9a42583e4110"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Results from Grid Search \n",
            "\n",
            " The best estimator across ALL searched params:\n",
            " LogisticRegression(C=2, class_weight='balanced')\n",
            "\n",
            " The best score across ALL searched params:\n",
            " 0.9010927023395163\n",
            "\n",
            " The best parameters across ALL searched params:\n",
            " {'C': 2, 'penalty': 'l2'}\n"
          ]
        }
      ],
      "source": [
        "print(\" Results from Grid Search \" )\n",
        "print(\"\\n The best estimator across ALL searched params:\\n\",logreg_KF.best_estimator_)\n",
        "print(\"\\n The best score across ALL searched params:\\n\",logreg_KF.best_score_)\n",
        "print(\"\\n The best parameters across ALL searched params:\\n\",logreg_KF.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f4cdca6",
      "metadata": {
        "id": "6f4cdca6"
      },
      "source": [
        "### Predict and evaluate using the best estimator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b91d3f57",
      "metadata": {
        "id": "b91d3f57"
      },
      "source": [
        "#### 1. Use the best estimator from the grid search to make predictions on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95542108",
      "metadata": {
        "id": "95542108"
      },
      "outputs": [],
      "source": [
        "logreg_be=LogisticRegression(C=2, class_weight='balanced', dual=False, fit_intercept=True,\n",
        "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
        "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
        "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
        "                   warm_start=False)\n",
        "\n",
        "logreg_be_cv=GridSearchCV(logreg_be,grid)\n",
        "logreg_be_cv.fit(X_test_tfidf_dtm,y_test)\n",
        "\n",
        "\n",
        "be_cv_y_pred_class_test = logreg_be_cv.predict(X_test_tfidf_dtm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa7a6443",
      "metadata": {
        "id": "aa7a6443"
      },
      "source": [
        "#### 2. What is the recall on the test set for the toxic comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c4bd110",
      "metadata": {
        "id": "5c4bd110",
        "outputId": "3afaf0a6-9229-43a9-f015-894428b0b344"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9870622635788385"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "be_recall = recall_score(y_test, be_cv_y_pred_class_test, average = \"macro\")\n",
        "be_recall"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "112eb833",
      "metadata": {
        "id": "112eb833"
      },
      "source": [
        "#### 3. What is the f_1 score?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77cca3ec",
      "metadata": {
        "id": "77cca3ec",
        "outputId": "85eba609-ec92-4038-e3d5-39628e25a918"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9223454001966874"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "be_f1_score = f1_score(y_test, be_cv_y_pred_class_test, average = \"macro\")\n",
        "be_f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2718131f",
      "metadata": {
        "id": "2718131f"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix=confusion_matrix(y_test, be_cv_y_pred_class_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3539a7a",
      "metadata": {
        "id": "a3539a7a",
        "outputId": "0c01191b-a84a-4c96-ff61-bf571f8ef1d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[7272  179]\n",
            " [   1  539]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baf1118d",
      "metadata": {
        "id": "baf1118d",
        "outputId": "ca56dbbb-6530-4e0d-b874-1005955a2606"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    non_hate       1.00      0.98      0.99      7451\n",
            "        hate       0.75      1.00      0.86       540\n",
            "\n",
            "    accuracy                           0.98      7991\n",
            "   macro avg       0.88      0.99      0.92      7991\n",
            "weighted avg       0.98      0.98      0.98      7991\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = ['non_hate', 'hate']\n",
        "print(classification_report(y_test, be_cv_y_pred_class_test,target_names=target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30906ee6",
      "metadata": {
        "id": "30906ee6"
      },
      "source": [
        "##### Applying best parameters on test dataset we get F1 score of 0.99."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4438a78c",
      "metadata": {
        "id": "4438a78c",
        "outputId": "f1242228-3166-4978-87d0-97ecb37956ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(50.722222222222214, 0.5, 'Truth')"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sn\n",
        "sn.heatmap(confusion_matrix, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09ac907d",
      "metadata": {
        "id": "09ac907d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "82b9d473",
        "68973826",
        "6ed92ec5",
        "cd9afd07"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
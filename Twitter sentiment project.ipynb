{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ab87d2f",
   "metadata": {
    "id": "3ab87d2f"
   },
   "source": [
    "## Help Twitter Combat Hate Speech Using NLP and ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eea0c4e",
   "metadata": {},
   "source": [
    "\n",
    "Twitter is the biggest platform where anybody and everybody can have their views heard. Some of these voices spread hate and negativity. Twitter is wary of its platform being used as a medium to spread hate.\n",
    "\n",
    "You are a data scientist at Twitter, and you will help Twitter in identifying the tweets with hate speech and removing them from the platform. You will use NLP techniques, perform specific cleanup for tweets data, and make a robust model.\n",
    "\n",
    "Domain: Social Media\n",
    "\n",
    "Analysis to be done: Clean up tweets and build a classification model by using NLP techniques, cleanup specific for tweets data, regularization and hyperparameter tuning using stratified k-fold and cross validation to get the best model.\n",
    "\n",
    "Content:\n",
    "\n",
    "id: identifier number of the tweet\n",
    "\n",
    "Label: 0 (non-hate) /1 (hate)\n",
    "\n",
    "Tweet: the text in the tweet\n",
    "\n",
    "Tasks:\n",
    "\n",
    "1, Load the tweets file using read_csv function from Pandas package.\n",
    "\n",
    "2, Get the tweets into a list for easy text cleanup and manipulation.\n",
    "\n",
    "To cleanup:\n",
    "\n",
    "--- Normalize the casing.\n",
    "\n",
    "--- Using regular expressions, remove user handles. These begin with '@’.\n",
    "\n",
    "--- Using regular expressions, remove URLs.\n",
    "\n",
    "--- Using TweetTokenizer from NLTK, tokenize the tweets into individual terms.\n",
    "\n",
    "--- Remove stop words.\n",
    "\n",
    "--- Remove redundant terms like ‘amp’, ‘rt’, etc.\n",
    "\n",
    "--- Remove ‘#’ symbols from the tweet while retaining the term.\n",
    "\n",
    "(4), Extra cleanup by removing terms with a length of 1.\n",
    "\n",
    "(5), Check out the top terms in the tweets:\n",
    "\n",
    "--- First, get all the tokenized terms into one large list.\n",
    "\n",
    "--- Use the counter and find the 10 most common terms.\n",
    "\n",
    "(6), Data formatting for predictive modeling:\n",
    "\n",
    "---Join the tokens back to form strings. This will be required for the vectorizers.\n",
    "\n",
    "---Assign x and y.\n",
    "\n",
    "---Perform train_test_split using sklearn.\n",
    "\n",
    "(7), We’ll use TF-IDF values for the terms as a feature to get into a vector space model.\n",
    "\n",
    "---Import TF-IDF vectorizer from sklearn.\n",
    "\n",
    "---Instantiate with a maximum of 5000 terms in your vocabulary.\n",
    "\n",
    "---Fit and apply on the train set.\n",
    "\n",
    "---Apply on the test set.\n",
    "\n",
    "(8), Model building: Ordinary Logistic Regression\n",
    "\n",
    "---Instantiate Logistic Regression from sklearn with default parameters.\n",
    "\n",
    "---Fit into the train data.\n",
    "\n",
    "---Make predictions for the train and the test set.\n",
    "\n",
    "(9), Model evaluation: Accuracy, recall, and f_1 score.\n",
    "\n",
    "Report the accuracy on the train set.\n",
    "\n",
    "---Report the recall on the train set: decent, high, or low.\n",
    "\n",
    "---Get the f1 score on the train set.\n",
    "\n",
    "(10), Looks like you need to adjust the class imbalance, as the model seems to focus on the 0s.\n",
    "\n",
    "---Adjust the appropriate class in the LogisticRegression model.\n",
    "\n",
    "(11), Train again with the adjustment and evaluate.\n",
    "\n",
    "---Train the model on the train set.\n",
    "\n",
    "---Evaluate the predictions on the train set: accuracy, recall, and f_1 score.\n",
    "\n",
    "(12), Regularization and Hyperparameter tuning:\n",
    "\n",
    "---Import GridSearch and StratifiedKFold because of class imbalance.\n",
    "\n",
    "---Provide the parameter grid to choose for ‘C’ and ‘penalty’ parameters.\n",
    "\n",
    "---Use a balanced class weight while instantiating the logistic regression.\n",
    "\n",
    "(13), Find the parameters with the best recall in cross-validation.\n",
    "\n",
    "---Choose ‘recall’ as the metric for scoring.\n",
    "\n",
    "---Choose a stratified 4 fold cross-validation scheme.\n",
    "\n",
    "---Fit into the train set.\n",
    "\n",
    "(14), What are the best parameters?\n",
    "\n",
    "(15), Predict and evaluate using the best estimator.\n",
    "\n",
    "---Use the best estimator from the grid search to make predictions on the test set.\n",
    "\n",
    "---What is the recall on the test set for the toxic comments?\n",
    "\n",
    "---What is the f_1 score?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5401faf",
   "metadata": {},
   "source": [
    "### import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b3d57ac",
   "metadata": {
    "id": "7b3d57ac"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import SklearnClassifier\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from subprocess import check_output\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import re\n",
    "import string "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3cf3cd",
   "metadata": {
    "id": "6f3cf3cd"
   },
   "source": [
    "## 1. Load tweets file using read_csv function from Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6f8c2d8",
   "metadata": {
    "id": "b6f8c2d8",
    "outputId": "46e9638a-3618-4bd1-f9da-b308b9eccd4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset\n",
    "Twitter_Data = pd.read_csv('TwitterHate.csv')\n",
    "Twitter_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fefd8e15",
   "metadata": {
    "id": "fefd8e15",
    "outputId": "684fc7a1-09e4-43c7-b585-9c7b1e420c98"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Twitter_Data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78a0beff",
   "metadata": {
    "id": "78a0beff",
    "outputId": "c0c72121-69fc-481c-e888-fd4c078e3345"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retain only neccessary columns\n",
    "Twitter_Data = Twitter_Data[['label','tweet']]\n",
    "Twitter_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bd76d69",
   "metadata": {
    "id": "2bd76d69",
    "outputId": "aa2fee81-0bfc-4550-8e5b-5bdbdb6369fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29720\n",
       "1     2242\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Twitter_Data.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29c1558",
   "metadata": {
    "id": "e29c1558"
   },
   "source": [
    "## 2. Get tweets into a list for easy text cleanup and manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3feb2ec5",
   "metadata": {
    "id": "3feb2ec5",
    "outputId": "4340588a-b2b0-4ed7-fbd6-0b6bfa719fbd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using tolist() on tweet column to make a list \n",
    "Tweets_List = Twitter_Data['tweet'].tolist()\n",
    "type(Tweets_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58fc2d79",
   "metadata": {
    "id": "58fc2d79",
    "outputId": "30d3d50d-83d6-4f69-bad1-a5648ac4d737"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweets_List[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972d05de",
   "metadata": {
    "id": "972d05de"
   },
   "source": [
    "## 3. Cleanup and manipulation tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee461d8",
   "metadata": {
    "id": "cee461d8"
   },
   "source": [
    "#### 1. Normalize the casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c642ca08",
   "metadata": {
    "id": "c642ca08",
    "outputId": "4464a0ca-e98f-41a5-9e1c-1c84bb2d3b21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run',\n",
       " \"@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\",\n",
       " '  bihday your majesty',\n",
       " '#model   i love u take with u all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91\\x85ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦  ',\n",
       " ' factsguide: society now    #motivation']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizing Tweets_List using lower() function\n",
    "for i in range(len(Tweets_List)):\n",
    "    Tweets_List[i] = Tweets_List[i].lower()\n",
    "    \n",
    "Tweets_List[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82db1b4a",
   "metadata": {
    "id": "82db1b4a"
   },
   "source": [
    "### Using regular expressions, remove user handles. These begin with '@’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d38cb16",
   "metadata": {
    "id": "6d38cb16",
    "outputId": "82e9571b-fb8b-4a23-d605-1e3945fb34d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run',\n",
       " \" user  user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\",\n",
       " '  bihday your majesty',\n",
       " '#model   i love u take with u all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91\\x85ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦  ',\n",
       " ' factsguide: society now    #motivation']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using replace() to remove @\n",
    "for i in range(len(Tweets_List)):\n",
    "    Tweets_List[i] = Tweets_List[i].replace('@',' ')\n",
    "\n",
    "Tweets_List[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed98ef16",
   "metadata": {
    "id": "ed98ef16"
   },
   "source": [
    "### 3. Using regular expressions remove URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dd63a46",
   "metadata": {
    "id": "0dd63a46",
    "outputId": "b28da5f4-f327-4409-fca5-44d29af3fbc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count=0\n",
    "for i in range(len(Tweets_List)): \n",
    "    fullstring = Tweets_List[i]\n",
    "    Char_check = 'urð'\n",
    "    if Char_check in fullstring:\n",
    "        #print(Tweets_List[i])\n",
    "        count = count+1\n",
    "    else:\n",
    "        #print('Not found!')\n",
    "        count = count \n",
    "        \n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ac2eef6",
   "metadata": {
    "id": "8ac2eef6",
    "outputId": "3044cc9f-df09-4bea-e259-5b44480db16b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using replace() to remove @\n",
    "for i in range(len(Tweets_List)):\n",
    "    Tweets_List[i] = Tweets_List[i].replace('urð±!!! ðððð",
    "ð¦ð¦ð¦',' ')\n",
    "\n",
    "    \n",
    "count=0\n",
    "for i in range(len(Tweets_List)): \n",
    "    fullstring = Tweets_List[i]\n",
    "    Char_check = 'urð'\n",
    "    if Char_check in fullstring:\n",
    "        print(Tweets_List[i])\n",
    "        count = count+1\n",
    "    else:\n",
    "        #print('Not found!')\n",
    "        count = count \n",
    "        \n",
    "count\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5688f4b0",
   "metadata": {
    "id": "5688f4b0"
   },
   "source": [
    "#### URL's has been replaced with ' ' and now there are no tweets with URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edaefef",
   "metadata": {
    "id": "9edaefef"
   },
   "source": [
    "## 4. Using TweetTokenizer from NLTK, tokenize the tweets into individual terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54e1b73f",
   "metadata": {
    "id": "54e1b73f",
    "outputId": "2b02bfaa-1af4-4010-f9de-f7b04efa1824"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['user',\n",
       "  'when',\n",
       "  'a',\n",
       "  'father',\n",
       "  'is',\n",
       "  'dysfunctional',\n",
       "  'and',\n",
       "  'is',\n",
       "  'so',\n",
       "  'selfish',\n",
       "  'he',\n",
       "  'drags',\n",
       "  'his',\n",
       "  'kids',\n",
       "  'into',\n",
       "  'his',\n",
       "  'dysfunction',\n",
       "  '.',\n",
       "  '#run'],\n",
       " ['user',\n",
       "  'user',\n",
       "  'thanks',\n",
       "  'for',\n",
       "  '#lyft',\n",
       "  'credit',\n",
       "  'i',\n",
       "  \"can't\",\n",
       "  'use',\n",
       "  'cause',\n",
       "  'they',\n",
       "  \"don't\",\n",
       "  'offer',\n",
       "  'wheelchair',\n",
       "  'vans',\n",
       "  'in',\n",
       "  'pdx',\n",
       "  '.',\n",
       "  '#disapointed',\n",
       "  '#getthanked']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list1.extend(list2)\n",
    "tknzr = TweetTokenizer()\n",
    "Tweets_Words = list();\n",
    "for i in range(len(Tweets_List)):\n",
    "    Words = tknzr.tokenize(Tweets_List[i])\n",
    "    Tweets_Words.append(Words)\n",
    "    \n",
    "Tweets_Words[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2655eec9",
   "metadata": {
    "id": "2655eec9"
   },
   "source": [
    "### 5. Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24eef81c",
   "metadata": {
    "id": "24eef81c"
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text\n",
    "\n",
    "Tweets_List_Tokens = remove_stopwords(Tweets_List)\n",
    "#Tweets_List_Tokens[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d53064",
   "metadata": {
    "id": "d9d53064"
   },
   "source": [
    "#### Stopwords has been removed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c677f7de",
   "metadata": {
    "id": "c677f7de"
   },
   "source": [
    "\n",
    "### 6. Remove redundant terms like ‘amp’, ‘rt’, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6775326",
   "metadata": {
    "id": "c6775326",
    "outputId": "cedb080c-615a-41e4-d560-fc169eb63bb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run',\n",
       " \" user  user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\",\n",
       " '  bihday your majesty',\n",
       " '#model   i love u take with u all the time in    ',\n",
       " ' factsguide: society now    #motivation']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using replace() to remove @\n",
    "\n",
    "for i in range(len(Tweets_List)):\n",
    "    Tweets_List[i] = Tweets_List[i].replace('amp',' ')\n",
    "    Tweets_List[i] = Tweets_List[i].replace('rt',' ')\n",
    "    Tweets_List[i] = Tweets_List[i].replace('etc',' ')\n",
    "\n",
    "Tweets_List[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b69dc866",
   "metadata": {
    "id": "b69dc866",
    "outputId": "72ff4089-d43a-4796-a817-0dd18d08f85b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291407"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using replace() to remove @\n",
    "count = 0\n",
    "for i in range(len(Tweets_List_Tokens)):\n",
    "    count = count+1\n",
    "    Tweets_List_Tokens[i] = Tweets_List_Tokens[i].replace('amp',' ')\n",
    "    Tweets_List_Tokens[i] = Tweets_List_Tokens[i].replace('rt',' ')\n",
    "    Tweets_List_Tokens[i] = Tweets_List_Tokens[i].replace('etc',' ')\n",
    "\n",
    "Tweets_List_Tokens[:5]\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec526a3",
   "metadata": {
    "id": "5ec526a3"
   },
   "source": [
    "#### amp, rt and etc has been removed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce83c80",
   "metadata": {
    "id": "6ce83c80"
   },
   "source": [
    "\n",
    "### 7. Remove ‘#’ symbols from the tweet while retaining the term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34b7c8b3",
   "metadata": {
    "id": "34b7c8b3",
    "outputId": "2697d41d-6a01-4290-df0e-ab78470772ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23522"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count=0\n",
    "for i in range(len(Tweets_List)): \n",
    "    fullstring = Tweets_List[i]\n",
    "    Char_check = '#'\n",
    "    if Char_check in fullstring:\n",
    "        #print(Tweets_List[i])\n",
    "        count = count+1\n",
    "    else:\n",
    "        #print('Not found!')\n",
    "        count = count \n",
    "        \n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229b8cb9",
   "metadata": {
    "id": "229b8cb9"
   },
   "source": [
    "#### There are 23522 tweets having #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "965eb94f",
   "metadata": {
    "id": "965eb94f",
    "outputId": "d312e303-714d-47df-a3de-50b8073c95be",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.    run',\n",
       " \" user  user thanks for  lyft credit i can't use cause they don't offer wheelchair vans in pdx.     disapointed  getthanked\",\n",
       " '  bihday your majesty',\n",
       " ' model   i love u take with u all the time in    ',\n",
       " ' factsguide: society now     motivation']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using replace() to remove #\n",
    "for i in range(len(Tweets_List)):\n",
    "    Tweets_List[i] = Tweets_List[i].replace('#',' ')\n",
    "                                            \n",
    "Tweets_List[:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd4f4b7f",
   "metadata": {
    "id": "cd4f4b7f",
    "outputId": "b866e8eb-7270-4939-d577-0dcd755ac7f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'user', 'father', 'dysfunct', 'selfish']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using replace() to remove #\n",
    "for i in range(len(Tweets_List_Tokens)):\n",
    "    Tweets_List_Tokens[i] = Tweets_List_Tokens[i].replace('#',' ')\n",
    "                                            \n",
    "Tweets_List_Tokens[:5]      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33d0e29",
   "metadata": {
    "id": "e33d0e29"
   },
   "source": [
    "#### # has been replaced with ' '\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5689bb",
   "metadata": {
    "id": "db5689bb"
   },
   "source": [
    "\n",
    "### 4. Extra cleanup by removing terms with a length of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f057b94d",
   "metadata": {
    "id": "f057b94d",
    "outputId": "123d095a-e2f9-4d93-8954-196688268858"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291407"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(Tweets_List_Tokens)):\n",
    "    #Tweets_List_Tokens[i] = Tweets_List_Tokens[i].replace('#',' ')\n",
    "    if len(Tweets_List_Tokens[i]) <= 1 :\n",
    "        Tweets_List_Tokens[i] = ''\n",
    "        #Word = Tweets_List_Tokens[i]\n",
    "\n",
    "len(Tweets_List_Tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57c21c5e",
   "metadata": {
    "id": "57c21c5e",
    "outputId": "ddab25b6-7c46-41ee-ba4f-4b32cb6f61d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27171\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(Tweets_List_Tokens)):\n",
    "    if Tweets_List_Tokens[i] == '' :\n",
    "        count = count+1\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2a2797f",
   "metadata": {
    "id": "b2a2797f"
   },
   "outputs": [],
   "source": [
    "def remove_values_from_list(the_list, val):\n",
    "    return [value for value in the_list if value != val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0cc6e17a",
   "metadata": {
    "id": "0cc6e17a",
    "outputId": "120821e0-e8c7-4fc3-ecdc-3086bdcf2075"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264236"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tweets_List_Tokens = list(filter(lambda a: a != 999999999, Tweets_List_Tokens))\n",
    "Tweets_List_Tokens = remove_values_from_list(Tweets_List_Tokens, '')\n",
    "len(Tweets_List_Tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5863366e",
   "metadata": {
    "id": "5863366e"
   },
   "source": [
    "### 5. Check out the top terms in the tweets:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25c5957",
   "metadata": {
    "id": "a25c5957"
   },
   "source": [
    "#### 1. First, get all the tokenized terms into one large list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6132b690",
   "metadata": {
    "id": "6132b690",
    "outputId": "3ab7a344-8d5d-4c0a-c111-21e18d99336b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Tweets_List_Tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75f5327",
   "metadata": {
    "id": "a75f5327"
   },
   "source": [
    "#### 2. Use the counter and find the 10 most common terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67df601f",
   "metadata": {
    "id": "67df601f",
    "outputId": "0611a9f2-b661-4758-ebc1-340a2970d970"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user', 17210),\n",
       " ('love', 3104),\n",
       " ('day', 2760),\n",
       " ('happi', 1983),\n",
       " ('thank', 1550),\n",
       " ('get', 1244),\n",
       " ('time', 1241),\n",
       " ('go', 1135),\n",
       " ('like', 1103),\n",
       " ('life', 1099)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "Tweets_List_Tokens_Count = collections.Counter(Tweets_List_Tokens)\n",
    "[(l,k) for k,l in sorted([(j,i) for i,j in Tweets_List_Tokens_Count.items()], reverse=True)][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d1384f",
   "metadata": {
    "id": "18d1384f"
   },
   "source": [
    "### 6. Data formatting for predictive modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b9a0949",
   "metadata": {
    "id": "4b9a0949",
    "outputId": "62d7b204-6b46-4119-fc46-bdc28da466b4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31962,)\n",
      "(31962,)\n"
     ]
    }
   ],
   "source": [
    "X = Twitter_Data.tweet\n",
    "y = Twitter_Data.label\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79c21e4",
   "metadata": {
    "id": "c79c21e4"
   },
   "source": [
    "#### 3. Perform train_test_split using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cd358be",
   "metadata": {
    "id": "3cd358be",
    "outputId": "b18729a4-681e-4e3a-bfab-5478e8e31733"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23971,)\n",
      "(7991,)\n",
      "(23971,)\n",
      "(7991,)\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training ans testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1e501a",
   "metadata": {
    "id": "5d1e501a"
   },
   "source": [
    "### 7. Use TF-IDF values for the terms as a feature to get into a vector space model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a30436b",
   "metadata": {
    "id": "8a30436b"
   },
   "source": [
    "#### 1. Import TF-IDF vectorizer from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdb683f9",
   "metadata": {
    "id": "cdb683f9"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3cbe6d",
   "metadata": {
    "id": "6b3cbe6d"
   },
   "source": [
    "#### 2. Instantiate with a maximum of 5000 terms in your vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ef31485",
   "metadata": {
    "id": "8ef31485"
   },
   "outputs": [],
   "source": [
    "# instantiate the vectorizer\n",
    "vect_tfidf = TfidfVectorizer(analyzer='word')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5db028c",
   "metadata": {
    "id": "d5db028c"
   },
   "source": [
    "#### 3. Fit and apply on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "092f0d12",
   "metadata": {
    "id": "092f0d12"
   },
   "outputs": [],
   "source": [
    "vect_tfidf.fit(X_train)\n",
    "X_train_tfidf_dtm = vect_tfidf.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da8e85be",
   "metadata": {
    "id": "da8e85be",
    "outputId": "703bb49b-490e-4382-fea2-cfc37e58fae5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000001</th>\n",
       "      <th>001</th>\n",
       "      <th>0099</th>\n",
       "      <th>00am</th>\n",
       "      <th>00h30</th>\n",
       "      <th>01</th>\n",
       "      <th>0115</th>\n",
       "      <th>01926889917</th>\n",
       "      <th>...</th>\n",
       "      <th>ðºð¾ñ</th>\n",
       "      <th>ð¼ð</th>\n",
       "      <th>ð½ð</th>\n",
       "      <th>ð¾ð</th>\n",
       "      <th>ð¾ð½ð</th>\n",
       "      <th>ð¾ð½ðµð</th>\n",
       "      <th>ð¾ñ</th>\n",
       "      <th>ó¾</th>\n",
       "      <th>øª</th>\n",
       "      <th>ø¹ù</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23966</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23967</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23968</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23969</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23970</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23971 rows × 34556 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        00  000  000001  001  0099  00am  00h30   01  0115  01926889917  ...  \\\n",
       "0      0.0  0.0     0.0  0.0   0.0   0.0    0.0  0.0   0.0          0.0  ...   \n",
       "1      0.0  0.0     0.0  0.0   0.0   0.0    0.0  0.0   0.0          0.0  ...   \n",
       "2      0.0  0.0     0.0  0.0   0.0   0.0    0.0  0.0   0.0          0.0  ...   \n",
       "3      0.0  0.0     0.0  0.0   0.0   0.0    0.0  0.0   0.0          0.0  ...   \n",
       "4      0.0  0.0     0.0  0.0   0.0   0.0    0.0  0.0   0.0          0.0  ...   \n",
       "...    ...  ...     ...  ...   ...   ...    ...  ...   ...          ...  ...   \n",
       "23966  0.0  0.0     0.0  0.0   0.0   0.0    0.0  0.0   0.0          0.0  ...   \n",
       "23967  0.0  0.0     0.0  0.0   0.0   0.0    0.0  0.0   0.0          0.0  ...   \n",
       "23968  0.0  0.0     0.0  0.0   0.0   0.0    0.0  0.0   0.0          0.0  ...   \n",
       "23969  0.0  0.0     0.0  0.0   0.0   0.0    0.0  0.0   0.0          0.0  ...   \n",
       "23970  0.0  0.0     0.0  0.0   0.0   0.0    0.0  0.0   0.0          0.0  ...   \n",
       "\n",
       "       ðºð¾ñ  ð¼ð  ð½ð  ð¾ð  ð¾ð½ð  ð¾ð½ðµð  ð¾ñ   ó¾   øª  ø¹ù  \n",
       "0        0.0  0.0  0.0  0.0    0.0      0.0  0.0  0.0  0.0  0.0  \n",
       "1        0.0  0.0  0.0  0.0    0.0      0.0  0.0  0.0  0.0  0.0  \n",
       "2        0.0  0.0  0.0  0.0    0.0      0.0  0.0  0.0  0.0  0.0  \n",
       "3        0.0  0.0  0.0  0.0    0.0      0.0  0.0  0.0  0.0  0.0  \n",
       "4        0.0  0.0  0.0  0.0    0.0      0.0  0.0  0.0  0.0  0.0  \n",
       "...      ...  ...  ...  ...    ...      ...  ...  ...  ...  ...  \n",
       "23966    0.0  0.0  0.0  0.0    0.0      0.0  0.0  0.0  0.0  0.0  \n",
       "23967    0.0  0.0  0.0  0.0    0.0      0.0  0.0  0.0  0.0  0.0  \n",
       "23968    0.0  0.0  0.0  0.0    0.0      0.0  0.0  0.0  0.0  0.0  \n",
       "23969    0.0  0.0  0.0  0.0    0.0      0.0  0.0  0.0  0.0  0.0  \n",
       "23970    0.0  0.0  0.0  0.0    0.0      0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[23971 rows x 34556 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe\n",
    "feature_names = vect_tfidf.get_feature_names_out ()\n",
    "pd.DataFrame(X_train_tfidf_dtm.toarray(), columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7405e77",
   "metadata": {
    "id": "a7405e77"
   },
   "source": [
    "#### 4. Apply on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11770851",
   "metadata": {
    "id": "11770851"
   },
   "outputs": [],
   "source": [
    "#vectorizer.transform\n",
    "#vect_tfidf.fit(X_test)\n",
    "X_test_tfidf_dtm = vect_tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd3d570b",
   "metadata": {
    "id": "fd3d570b",
    "outputId": "9e87324a-88fe-4feb-ba18-2ea12ade4981"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000001</th>\n",
       "      <th>001</th>\n",
       "      <th>0099</th>\n",
       "      <th>00am</th>\n",
       "      <th>00h30</th>\n",
       "      <th>01</th>\n",
       "      <th>0115</th>\n",
       "      <th>01926889917</th>\n",
       "      <th>...</th>\n",
       "      <th>ðºð¾ñ</th>\n",
       "      <th>ð¼ð</th>\n",
       "      <th>ð½ð</th>\n",
       "      <th>ð¾ð</th>\n",
       "      <th>ð¾ð½ð</th>\n",
       "      <th>ð¾ð½ðµð</th>\n",
       "      <th>ð¾ñ</th>\n",
       "      <th>ó¾</th>\n",
       "      <th>øª</th>\n",
       "      <th>ø¹ù</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7986</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7987</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7988</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7989</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7990</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7991 rows × 34556 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  000  000001  001  0099  00am  00h30   01  0115  01926889917  ...  \\\n",
       "0     0.0  0.0     0.0  0.0   0.0   0.0    0.0  0.0   0.0          0.0  ...   \n",
       "1     0.0  0.0     0.0  0.0   0.0   0.0    0.0  0.0   0.0          0.0  ...   \n",
       "2     0.0  0.0     0.0  0.0   0.0   0.0    0.0  0.0   0.0          0.0  ...   \n",
       "3     0.0  0.0     0.0  0.0   0.0   0.0    0.0  0.0   0.0          0.0  ...   \n",
       "4     0.0  0.0     0.0  0.0   0.0   0.0    0.0  0.0   0.0          0.0  ...   \n",
       "...   ...  ...     ...  ...   ...   ...    ...  ...   ...          ...  ...   \n",
       "7986  0.0  0.0     0.0  0.0   0.0   0.0    0.0  0.0   0.0          0.0  ...   \n",
       "7987  0.0  0.0     0.0  0.0   0.0   0.0    0.0  0.0   0.0          0.0  ...   \n",
       "7988  0.0  0.0     0.0  0.0   0.0   0.0    0.0  0.0   0.0          0.0  ...   \n",
       "7989  0.0  0.0     0.0  0.0   0.0   0.0    0.0  0.0   0.0          0.0  ...   \n",
       "7990  0.0  0.0     0.0  0.0   0.0   0.0    0.0  0.0   0.0          0.0  ...   \n",
       "\n",
       "      ðºð¾ñ  ð¼ð  ð½ð  ð¾ð  ð¾ð½ð  ð¾ð½ðµð  ð¾ñ   ó¾   øª  ø¹ù  \n",
       "0       0.0  0.0  0.0  0.0    0.0      0.0  0.0  0.0  0.0  0.0  \n",
       "1       0.0  0.0  0.0  0.0    0.0      0.0  0.0  0.0  0.0  0.0  \n",
       "2       0.0  0.0  0.0  0.0    0.0      0.0  0.0  0.0  0.0  0.0  \n",
       "3       0.0  0.0  0.0  0.0    0.0      0.0  0.0  0.0  0.0  0.0  \n",
       "4       0.0  0.0  0.0  0.0    0.0      0.0  0.0  0.0  0.0  0.0  \n",
       "...     ...  ...  ...  ...    ...      ...  ...  ...  ...  ...  \n",
       "7986    0.0  0.0  0.0  0.0    0.0      0.0  0.0  0.0  0.0  0.0  \n",
       "7987    0.0  0.0  0.0  0.0    0.0      0.0  0.0  0.0  0.0  0.0  \n",
       "7988    0.0  0.0  0.0  0.0    0.0      0.0  0.0  0.0  0.0  0.0  \n",
       "7989    0.0  0.0  0.0  0.0    0.0      0.0  0.0  0.0  0.0  0.0  \n",
       "7990    0.0  0.0  0.0  0.0    0.0      0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[7991 rows x 34556 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe\n",
    "feature_names_test = vect_tfidf.get_feature_names_out ()\n",
    "pd.DataFrame(X_test_tfidf_dtm.toarray(), columns=feature_names_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d385e20",
   "metadata": {
    "id": "4d385e20"
   },
   "source": [
    "### 8. Model building: Ordinary Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219023a6",
   "metadata": {
    "id": "219023a6"
   },
   "source": [
    "#### 1. Instantiate Logistic Regression from sklearn with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f37382a7",
   "metadata": {
    "id": "f37382a7"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d9203fb",
   "metadata": {
    "id": "4d9203fb",
    "outputId": "8e36e6ee-8114-4b2a-97d3-939e596d5372"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_tfidf_dtm, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92385818",
   "metadata": {
    "id": "92385818"
   },
   "source": [
    "#### 3. Make predictions for the train and the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00087ff3",
   "metadata": {
    "id": "00087ff3"
   },
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class_train = lr.predict(X_train_tfidf_dtm)\n",
    "y_pred_class_test = lr.predict(X_test_tfidf_dtm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c841b8da",
   "metadata": {
    "id": "c841b8da"
   },
   "source": [
    "### 9. Model evaluation: Accuracy, recall, and f_1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1786484a",
   "metadata": {
    "id": "1786484a"
   },
   "source": [
    "#### 1. Report the accuracy on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78f4f514",
   "metadata": {
    "id": "78f4f514",
    "outputId": "9233120a-d17e-47de-f431-a2c2e3a8ea01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9509824371115098"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate accuracy of class predictions\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score_train = accuracy_score(y_train, y_pred_class_train)\n",
    "accuracy_score_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c556a742",
   "metadata": {
    "id": "c556a742"
   },
   "source": [
    "#### 2. Report the recall on the train set: decent, high, or low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2e9eb3f",
   "metadata": {
    "id": "a2e9eb3f",
    "outputId": "52f3c2ef-f432-44a9-db40-cf583898bc40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6599729279619632"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall_metric = recall_score(y_train, y_pred_class_train, average = \"macro\")\n",
    "recall_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3560b1e0",
   "metadata": {
    "id": "3560b1e0"
   },
   "source": [
    "#### 3. Get the f1 score on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cbc0d761",
   "metadata": {
    "id": "cbc0d761",
    "outputId": "a0f9767a-2bcd-434c-a95f-48b67e86bc8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7279843179634792"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score = f1_score(y_train, y_pred_class_train, average = \"macro\")\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6b82821",
   "metadata": {
    "id": "d6b82821",
    "outputId": "667fde06-ccf1-4fcb-9976-adeeb7a4d13d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22250    19]\n",
      " [ 1156   546]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_train,y_pred_class_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a80cf6",
   "metadata": {
    "id": "68a80cf6"
   },
   "source": [
    "### 10. Adjust the class imbalance, as the model seems to focus on the 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a1c383",
   "metadata": {
    "id": "22a1c383"
   },
   "source": [
    "#### 1. Adjust the appropriate class in the LogisticRegression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7dc4322",
   "metadata": {
    "id": "c7dc4322"
   },
   "outputs": [],
   "source": [
    "wlr = LogisticRegression(random_state=1, class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08adcfbf",
   "metadata": {
    "id": "08adcfbf"
   },
   "source": [
    "### 11. Train again with the adjustment and evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b9d473",
   "metadata": {
    "id": "82b9d473"
   },
   "source": [
    "####1. Train the model on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe0eac16",
   "metadata": {
    "id": "fe0eac16"
   },
   "outputs": [],
   "source": [
    "wlr.fit(X_train_tfidf_dtm, y_train)\n",
    "\n",
    "wlr_y_pred_class_train = wlr.predict(X_train_tfidf_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68973826",
   "metadata": {
    "id": "68973826"
   },
   "source": [
    "#### 2. Evaluate the predictions on the train set: accuracy, recall, and f_1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "404bdb8f",
   "metadata": {
    "id": "404bdb8f",
    "outputId": "1480400a-bf03-4e32-d0a5-fc8f0fd3c9c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.965875432814651"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wlr_accuracy_score_train = accuracy_score(y_train, wlr_y_pred_class_train)\n",
    "wlr_accuracy_score_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf870bbe",
   "metadata": {
    "id": "bf870bbe",
    "outputId": "583650aa-154d-4e7a-f1ab-8f36cc87d485"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9772925524086722"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wlr_recall_metric = recall_score(y_train, wlr_y_pred_class_train, average = \"macro\")\n",
    "wlr_recall_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "862d86e6",
   "metadata": {
    "id": "862d86e6",
    "outputId": "13565e45-6bad-4e9e-a0e3-d5303343cf80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8930384907600268"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "wlr_f1_score = f1_score(y_train, wlr_y_pred_class_train, average = \"macro\")\n",
    "wlr_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "faaa2553",
   "metadata": {
    "id": "faaa2553",
    "outputId": "cff55b49-4edb-49b6-f4c4-796c29c22beb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21467   802]\n",
      " [   16  1686]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_train,wlr_y_pred_class_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72f8fa3",
   "metadata": {
    "id": "d72f8fa3"
   },
   "source": [
    "##### By changing class_weight from none to balanced, F1 score has improved to 0.89 from 0.72 and FN has reduced to 16 from 1156 and FP has increased to 802 from 19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f757306a",
   "metadata": {
    "id": "f757306a"
   },
   "source": [
    "### 12. Regularization and Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca69a55",
   "metadata": {
    "id": "fca69a55"
   },
   "source": [
    "#### 1. Import GridSearch and StratifiedKFold because of class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9ce3fc9e",
   "metadata": {
    "id": "9ce3fc9e"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf0bf8b",
   "metadata": {
    "id": "bcf0bf8b"
   },
   "source": [
    "#### 2. Provide the parameter grid to choose for ‘C’ and ‘penalty’ parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42e789c8",
   "metadata": {
    "id": "42e789c8"
   },
   "outputs": [],
   "source": [
    "grid={\"C\": [1, 2], \"penalty\":[\"l2\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5428dc13",
   "metadata": {
    "id": "5428dc13"
   },
   "source": [
    "#### 3. Use a balanced class weight while instantiating the logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f002408",
   "metadata": {
    "id": "1f002408"
   },
   "outputs": [],
   "source": [
    "logreg=LogisticRegression(class_weight=\"balanced\")\n",
    "logreg_cv=GridSearchCV(logreg,grid)\n",
    "logreg_cv.fit(X_train_tfidf_dtm,y_train)\n",
    "cv_y_pred_class_train = logreg_cv.predict(X_train_tfidf_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8abaaa4b",
   "metadata": {
    "id": "8abaaa4b",
    "outputId": "ac694d5c-42bf-456b-c9e1-71edc0c47a9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9765550039631221"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wlr_accuracy_score_train = accuracy_score(y_train, cv_y_pred_class_train)\n",
    "wlr_accuracy_score_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "47a0d47d",
   "metadata": {
    "id": "47a0d47d",
    "outputId": "9a563c0a-113d-4ab3-c7f8-2b04f1f8fdd2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9860249653328157"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wlr_recall_metric = recall_score(y_train, cv_y_pred_class_train, average = \"macro\")\n",
    "wlr_recall_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aaedc7b1",
   "metadata": {
    "id": "aaedc7b1",
    "outputId": "fd7d1357-c4bd-4cd9-aa16-a96f3edf7996"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9225802588993639"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "wlr_f1_score = f1_score(y_train, cv_y_pred_class_train, average = \"macro\")\n",
    "wlr_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "10c28dd6",
   "metadata": {
    "id": "10c28dd6",
    "outputId": "83202b9d-17fc-4a38-f898-ee503d3532d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21467   802]\n",
      " [   16  1686]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_train,wlr_y_pred_class_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "05f842f5",
   "metadata": {
    "id": "05f842f5",
    "outputId": "9871c1fb-b0da-4077-d2f6-8a9f40d6931c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21712   557]\n",
      " [    5  1697]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_train,cv_y_pred_class_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75623b61",
   "metadata": {
    "id": "75623b61"
   },
   "source": [
    "##### By applying gridsearch, F1 score has improved to 0.92 from 0.89 and FN has reduced to 5 from 16 and FP has reduced to 557 from 802"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed92ec5",
   "metadata": {
    "id": "6ed92ec5"
   },
   "source": [
    "### 13. Find the parameters with the best recall in cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13ae645",
   "metadata": {
    "id": "b13ae645"
   },
   "source": [
    "#### 1. Choose ‘recall’ as the metric for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "28c0b010",
   "metadata": {
    "id": "28c0b010"
   },
   "outputs": [],
   "source": [
    "logreg_KF=GridSearchCV(logreg,grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89722df7",
   "metadata": {
    "id": "89722df7"
   },
   "source": [
    "#### 2. Choose stratified 4 fold cross validation scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "85faa2a8",
   "metadata": {
    "id": "85faa2a8",
    "outputId": "bbd1fe3c-e8c8-4636-f55d-632ffc88acd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from numpy import array\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "kf = KFold(n_splits=4)\n",
    "kf.get_n_splits(Twitter_Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d295b5e0",
   "metadata": {
    "id": "d295b5e0"
   },
   "source": [
    "#### 3. Fit into the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a907a7a5",
   "metadata": {
    "id": "a907a7a5",
    "outputId": "7d435d6d-91fa-4119-a838-5e6c145d75ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score for fold1 is 0.9851502155496935\n",
      "Recall score for fold2 is 0.9845545135522261\n",
      "Recall score for fold3 is 0.9836963185597225\n",
      "Recall score for fold4 is 0.9852769832498716\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for train_index, test_index in kf.split(Twitter_Data):\n",
    "    KF_X_train, KF_X_test, KF_y_train, KF_y_test = Twitter_Data.tweet[train_index], Twitter_Data.tweet[test_index],\\\n",
    "    Twitter_Data.label[train_index],Twitter_Data.label[test_index]\n",
    "    KF_X_train_tfidf_dtm = vect_tfidf.transform(KF_X_train)\n",
    "    KF_X_test_tfidf_dtm = vect_tfidf.transform(KF_X_test)\n",
    "    count=count+1\n",
    "    logreg_KF.fit(KF_X_train_tfidf_dtm,KF_y_train)\n",
    "    KF_cv_y_pred_class_train = logreg_KF.predict(KF_X_train_tfidf_dtm)\n",
    "    KF_recall_metric = recall_score(KF_y_train, KF_cv_y_pred_class_train, average = \"macro\")\n",
    "    print(\"Recall score for fold\" + str(count) + \" is \" + str(KF_recall_metric)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9afd07",
   "metadata": {
    "id": "cd9afd07"
   },
   "source": [
    "#### Recall score is pretty consistent across all 4 data distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2046a23",
   "metadata": {
    "id": "e2046a23"
   },
   "source": [
    "### 14. What are the best parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9a6a53a2",
   "metadata": {
    "id": "9a6a53a2",
    "outputId": "817c68d4-9f56-4bc2-ace1-9a42583e4110"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " LogisticRegression(C=2, class_weight='balanced')\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.9458116789191215\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'C': 2, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",logreg_KF.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",logreg_KF.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",logreg_KF.best_params_) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4cdca6",
   "metadata": {
    "id": "6f4cdca6"
   },
   "source": [
    "### 15. Predict and evaluate using the best estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91d3f57",
   "metadata": {
    "id": "b91d3f57"
   },
   "source": [
    "#### 1. Use the best estimator from the grid search to make predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "95542108",
   "metadata": {
    "id": "95542108"
   },
   "outputs": [],
   "source": [
    "logreg_be=LogisticRegression(C=2, class_weight='balanced', dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "\n",
    "logreg_be_cv=GridSearchCV(logreg_be,grid)\n",
    "logreg_be_cv.fit(X_test_tfidf_dtm,y_test)\n",
    "\n",
    "\n",
    "be_cv_y_pred_class_test = logreg_be_cv.predict(X_test_tfidf_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7a6443",
   "metadata": {
    "id": "aa7a6443"
   },
   "source": [
    "#### 2. What is the recall on the test set for the toxic comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5c4bd110",
   "metadata": {
    "id": "5c4bd110",
    "outputId": "3afaf0a6-9229-43a9-f015-894428b0b344"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9869951584922729"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "be_recall = recall_score(y_test, be_cv_y_pred_class_test, average = \"macro\")\n",
    "be_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112eb833",
   "metadata": {
    "id": "112eb833"
   },
   "source": [
    "#### 3. What is the f_1 score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "77cca3ec",
   "metadata": {
    "id": "77cca3ec",
    "outputId": "85eba609-ec92-4038-e3d5-39628e25a918"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9219707085416435"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "be_f1_score = f1_score(y_test, be_cv_y_pred_class_test, average = \"macro\")\n",
    "be_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2718131f",
   "metadata": {
    "id": "2718131f"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix=confusion_matrix(y_test, be_cv_y_pred_class_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a3539a7a",
   "metadata": {
    "id": "a3539a7a",
    "outputId": "0c01191b-a84a-4c96-ff61-bf571f8ef1d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7271  180]\n",
      " [   1  539]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "baf1118d",
   "metadata": {
    "id": "baf1118d",
    "outputId": "ca56dbbb-6530-4e0d-b874-1005955a2606"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      7451\n",
      "           1       0.75      1.00      0.86       540\n",
      "\n",
      "    accuracy                           0.98      7991\n",
      "   macro avg       0.87      0.99      0.92      7991\n",
      "weighted avg       0.98      0.98      0.98      7991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, be_cv_y_pred_class_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30906ee6",
   "metadata": {
    "id": "30906ee6"
   },
   "source": [
    "##### Applying best parameters on test dataset we get F1 score of 0.99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4438a78c",
   "metadata": {
    "id": "4438a78c",
    "outputId": "f1242228-3166-4978-87d0-97ecb37956ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "sn.heatmap(confusion_matrix, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ac907d",
   "metadata": {
    "id": "09ac907d"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ed98ef16",
    "5688f4b0",
    "2655eec9",
    "d9d53064",
    "c677f7de",
    "5ec526a3",
    "6ce83c80",
    "229b8cb9",
    "e33d0e29",
    "db5689bb",
    "5863366e",
    "a25c5957",
    "a75f5327",
    "18d1384f",
    "c79c21e4",
    "5d1e501a",
    "8a30436b",
    "6b3cbe6d",
    "d5db028c",
    "a7405e77",
    "4d385e20",
    "219023a6",
    "92385818",
    "c841b8da",
    "1786484a",
    "c556a742",
    "3560b1e0",
    "68a80cf6",
    "22a1c383",
    "08adcfbf",
    "82b9d473",
    "68973826",
    "f757306a",
    "fca69a55",
    "bcf0bf8b",
    "5428dc13",
    "6ed92ec5",
    "b13ae645",
    "89722df7",
    "d295b5e0",
    "cd9afd07",
    "e2046a23",
    "b91d3f57",
    "aa7a6443"
   ],
   "name": "Twitter_ham(new).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
